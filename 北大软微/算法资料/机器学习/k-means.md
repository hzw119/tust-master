1. ## k-means: 是一种无监督学习

2. ## k-means 算法的具体步骤：

   1. 数据预处理：归一化，离群点处理
   2. 随机选取K个簇中心，记为$\mu^{(0)}_{1} \mu^{(0)}_{2} \mu^{(0)}_{3}....\mu^{(0)}_{k}$
   3. 定义代价函数:**loss func**
   4. 开始迭代，迭代次数为x，重复下面过程直到 loss func 收敛
      1. 对于每一个样本，将其分配到距离最近的簇
      2. 对于每一个簇，重新计算该类簇的中心：簇内所有点的平均值

3. ## K-means 的优缺点：

   缺点：

   1. 需要人工预先确定**K值**，此K值未必最优
   2. K均值往往会收敛到**局部最优**：未必是个凸优化问题
   3. 易受到噪点的影响

   优点：

   1. 时间复杂度：**O(NKt)接近线性**，N为样本点个数，K是簇多少，t为迭代次数
   2. 对于大数据集，K均值聚类算法相对是高效的。

4. ## K-means：算法调优

   1. 归一化，离群点处理
   2. 合理选择K值：**手肘法**
   3. 采用核方法：通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中。

5. ## 改进的模型

   1. K-means++:

      初始簇中心的选择：

      假设已经选取了n个簇中心，在选取第n+1个簇中心时，尽量选择离之前的n个簇中心较远的点做下一个簇中心。

   2. ISODATA：

      动态**K**值，当属于某个类别的样本点过少时，把该类别去除，当某个类别的样本数过多且分布较为**分散**时，把该类别分裂为两个类别。

      如何衡量分散程度：样本点与簇中心的方差和的大小

      

6. ## KNN VS. K-means

| KNN                                                          | K-means                             |
| ------------------------------------------------------------ | ----------------------------------- |
| 分类、监督、训练集有label                                    | 聚类、无监督、训练集无label         |
| 没有训练过程                                                 | 有loss function，有训练（迭代过程） |
| K是指：分类结果取决于离样本点最近的k个样本点的最多的所属类别 | K是指 将数据聚类成几类              |
| 给定一个点在数据集种找离他最近的点                           |                                     |





**密度聚类**

**分类和聚类的区别**

**分类和回归的区别**：有无监督、有无标签

  分类：将输入x映射到类标签中

  回归：将输入x映射到一个y值上

